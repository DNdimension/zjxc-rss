import requests
from bs4 import BeautifulSoup
from feedgen.feed import FeedGenerator
from datetime import datetime
import pytz
import os

# ===== é…ç½®åŒº =====
TARGET_URL = "https://zjnews.zjol.com.cn/zjxc/"
OUTPUT_FILE = "docs/rss.xml"
MAX_ARTICLES = 30  # æŠ“å–æœ€æ–°30ç¯‡

# RSSé¢‘é“ä¿¡æ¯
BLOG_NAME = "æµ™æ±Ÿå®£ä¼ "
BLOG_LINK = TARGET_URL
BLOG_DESCRIPTION = "è‡ªåŠ¨ç”Ÿæˆçš„æµ™æ±Ÿå®£ä¼  RSS è®¢é˜…æºï¼ˆåŸºäºçœŸå®ç½‘é¡µç»“æ„ï¼‰"

def fetch_articles():
    """æŠ“å–ç½‘é¡µï¼Œæå–æ–‡ç« åˆ—è¡¨ï¼ˆç²¾ç¡®åŒ¹é…å®é™…HTMLç»“æ„ï¼‰"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    
    try:
        print(f"æ­£åœ¨æŠ“å–: {TARGET_URL}")
        response = requests.get(TARGET_URL, headers=headers, timeout=15)
        response.encoding = 'utf-8'
        soup = BeautifulSoup(response.text, 'html.parser')
    except Exception as e:
        print(f"æŠ“å–å¤±è´¥: {e}")
        return []

    articles = []
    
    # ç²¾ç¡®æ‰¾åˆ°æ–‡ç« åˆ—è¡¨å®¹å™¨
    ul_container = soup.find('ul', class_='listUl')
    if not ul_container:
        print("é”™è¯¯ï¼šæœªæ‰¾åˆ° class='listUl' çš„åˆ—è¡¨å®¹å™¨")
        return []
    
    # éå†æ¯ä¸ª li.listLi
    for li in ul_container.find_all('li', class_='listLi'):
        # 1. æå–æ—¶é—´
        span_time = li.find('span', class_='listSpan')
        if not span_time:
            continue
        time_str = span_time.get_text(strip=True)  # ä¾‹å¦‚ "2026å¹´02æœˆ23æ—¥12æ—¶"
        
        # 2. æå–é“¾æ¥å’Œæ ‡é¢˜
        a_tag = li.find('a', href=True)
        if not a_tag:
            continue
        title = a_tag.get_text(strip=True)
        href = a_tag['href']
        
        # 3. è¡¥å…¨é“¾æ¥ï¼ˆå¤„ç†ä»¥ // å¼€å¤´çš„ç›¸å¯¹åœ°å€ï¼‰
        if href.startswith('//'):
            full_link = 'https:' + href
        elif href.startswith('/'):
            full_link = 'https://zjnews.zjol.com.cn' + href
        else:
            full_link = href
        
        # 4. è§£ææ—¶é—´
        try:
            # å°† "2026å¹´02æœˆ23æ—¥12æ—¶" è½¬æ¢ä¸º "2026-02-23 12"
            clean_time = time_str.replace('å¹´', '-').replace('æœˆ', '-').replace('æ—¥', ' ').replace('æ—¶', '')
            pub_time = datetime.strptime(clean_time, "%Y-%m-%d %H")
            # è®¾ç½®ä¸ºä¸œå…«åŒº
            pub_time = pub_time.replace(tzinfo=pytz.timezone('Asia/Shanghai'))
        except Exception as e:
            print(f"æ—¶é—´è§£æå¤±è´¥: {time_str}ï¼Œé”™è¯¯: {e}")
            continue
        
        articles.append({
            'title': title,
            'link': full_link,
            'pub_time': pub_time,
            'description': title  # å…ˆç”¨æ ‡é¢˜ä»£æ›¿ï¼Œå¯åç»­ä¼˜åŒ–ä¸ºæŠ“å–æ­£æ–‡
        })
    
    # æŒ‰æ—¶é—´å€’åºæ’åˆ—ï¼ˆç½‘é¡µæœ¬èº«å·²å€’åºï¼Œä½†ä»¥é˜²ä¸‡ä¸€ï¼‰
    articles.sort(key=lambda x: x['pub_time'], reverse=True)
    
    print(f"æˆåŠŸæŠ“å–åˆ° {len(articles)} ç¯‡æ–‡ç« ")
    if articles:
        print(f"ç¤ºä¾‹: {articles[0]['title']} - {articles[0]['pub_time']}")
    
    return articles[:MAX_ARTICLES]

def generate_rss(articles):
    """ç”Ÿæˆ RSS 2.0 æ–‡ä»¶"""
    if not articles:
        print("æ²¡æœ‰æ–‡ç« ï¼Œä¸ç”Ÿæˆ RSS")
        return False
    
    fg = FeedGenerator()
    fg.title(BLOG_NAME)
    fg.link(href=BLOG_LINK, rel='alternate')
    fg.description(BLOG_DESCRIPTION)
    fg.language('zh-CN')
    
    for art in articles:
        fe = fg.add_entry()
        fe.title(art['title'])
        fe.link(href=art['link'])
        fe.description(art['description'])
        fe.pubDate(art['pub_time'])
        fe.guid(art['link'], permalink=True)  # ç”¨é“¾æ¥ä½œä¸ºå”¯ä¸€ID
    
    # ç”Ÿæˆ RSS æ–‡ä»¶
    fg.rss_file(OUTPUT_FILE, pretty=True)
    print(f"âœ… RSS æ–‡ä»¶å·²ç”Ÿæˆ: {OUTPUT_FILE}")
    return True

if __name__ == "__main__":
    print("å¼€å§‹æŠ“å–æµ™æ±Ÿå®£ä¼ æ–‡ç« ...")
    articles = fetch_articles()
    if articles:
        generate_rss(articles)
        abs_path = os.path.abspath(OUTPUT_FILE)
        print(f"ğŸ“ æ–‡ä»¶ä¿å­˜è·¯å¾„: {abs_path}")
        print("ä½ å¯ä»¥ç”¨ RSS é˜…è¯»å™¨æ‰“å¼€æ­¤æ–‡ä»¶æµ‹è¯•")
    else:
        print("âŒ æœªèƒ½æŠ“å–åˆ°æ–‡ç« ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–ç½‘ç«™æ˜¯å¦æ”¹ç‰ˆ")